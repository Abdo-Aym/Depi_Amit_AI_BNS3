{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "odSFD1t3CUG8"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b247rjbC2-u",
        "outputId": "dfa2b492-8e88-4ae9-e872-308999b92480"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Abdallah.Ayman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Abdallah.Ayman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS33pE0JDRnd",
        "outputId": "84bb7e2f-5ab9-4118-d45b-fba8e3c0dc55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to\n",
            "[nltk_data]     C:\\Users\\Abdallah.Ayman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('twitter_samples')\n",
        "from nltk.corpus import twitter_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VIAO_6-PDgZ3"
      },
      "outputs": [],
      "source": [
        "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4iSrf_ND0W0",
        "outputId": "db514a75-11f2-42b1-8e31-6bfefc23c161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000\n",
            "5000\n"
          ]
        }
      ],
      "source": [
        "print(len(positive_tweets))\n",
        "print(len(negative_tweets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FQjQXbDD4aF",
        "outputId": "601949f4-5074-43e6-f5f9-e465e570b489"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
            "<>:4: SyntaxWarning: invalid escape sequence '\\/'\n",
            "<>:5: SyntaxWarning: invalid escape sequence '\\?'\n",
            "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:7: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:11: SyntaxWarning: invalid escape sequence '\\]'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
            "<>:4: SyntaxWarning: invalid escape sequence '\\/'\n",
            "<>:5: SyntaxWarning: invalid escape sequence '\\?'\n",
            "<>:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:7: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:11: SyntaxWarning: invalid escape sequence '\\]'\n",
            "C:\\Users\\Abdallah.Ayman\\AppData\\Local\\Temp\\ipykernel_1548\\2585229808.py:3: SyntaxWarning: invalid escape sequence '\\w'\n",
            "  tweet=re.sub('(#|@)\\w*',\"\",tweet)# \\w [a-z|A_Z|0-9|_] #remoce hashtage ,username\n",
            "C:\\Users\\Abdallah.Ayman\\AppData\\Local\\Temp\\ipykernel_1548\\2585229808.py:4: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  tweet=re.sub(\"https?:\\/\\/\\S+\",\"\",tweet) #remove hyperlink\n",
            "C:\\Users\\Abdallah.Ayman\\AppData\\Local\\Temp\\ipykernel_1548\\2585229808.py:5: SyntaxWarning: invalid escape sequence '\\?'\n",
            "  tweet=re.sub(\"(\\?|!)+\",\" \",tweet) #remve (?!)\n",
            "C:\\Users\\Abdallah.Ayman\\AppData\\Local\\Temp\\ipykernel_1548\\2585229808.py:6: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  tweet=re.sub(\"\\s\\d+\\s\",\"\",tweet) # 33\n",
            "C:\\Users\\Abdallah.Ayman\\AppData\\Local\\Temp\\ipykernel_1548\\2585229808.py:7: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  tweet=re.sub(\"(\\.|\\,)+\",\"\",tweet) #remove . ,\n",
            "C:\\Users\\Abdallah.Ayman\\AppData\\Local\\Temp\\ipykernel_1548\\2585229808.py:8: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  tweet=re.sub(\"^\\s+\",\"\",tweet) #remove space ^ >> start of string\n",
            "C:\\Users\\Abdallah.Ayman\\AppData\\Local\\Temp\\ipykernel_1548\\2585229808.py:9: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  tweet=re.sub(\"\\s+$\",\"\",tweet)#remove space  $ >> at the end of the string\n",
            "C:\\Users\\Abdallah.Ayman\\AppData\\Local\\Temp\\ipykernel_1548\\2585229808.py:11: SyntaxWarning: invalid escape sequence '\\]'\n",
            "  tweet=re.sub(\"[_:()\\\\\\]\",\"\",tweet)\n"
          ]
        }
      ],
      "source": [
        "def clean_text(tweet):\n",
        "    #clean text\n",
        "    tweet=re.sub('(#|@)\\w*',\"\",tweet)# \\w [a-z|A_Z|0-9|_] #remoce hashtage ,username\n",
        "    tweet=re.sub(\"https?:\\/\\/\\S+\",\"\",tweet) #remove hyperlink\n",
        "    tweet=re.sub(\"(\\?|!)+\",\" \",tweet) #remve (?!)\n",
        "    tweet=re.sub(\"\\s\\d+\\s\",\"\",tweet) # 33\n",
        "    tweet=re.sub(\"(\\.|\\,)+\",\"\",tweet) #remove . ,\n",
        "    tweet=re.sub(\"^\\s+\",\"\",tweet) #remove space ^ >> start of string\n",
        "    tweet=re.sub(\"\\s+$\",\"\",tweet)#remove space  $ >> at the end of the string\n",
        "    tweet=re.sub(\":\",\"\",tweet)\n",
        "    tweet=re.sub(\"[_:()\\\\\\]\",\"\",tweet)\n",
        "\n",
        "    return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5r8wFwKoEP9a"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HwnEU8YZEkJd"
      },
      "outputs": [],
      "source": [
        "def process_sentence(tweets):\n",
        "  clean_tweets = []\n",
        "  for tweet in tweets:\n",
        "    tweet =  clean_text(tweet)\n",
        "    tweet = nltk.word_tokenize(tweet)\n",
        "    c_tweets = [word.lower() for word in tweet if word.lower() not in stop_words]\n",
        "    ps= PorterStemmer()\n",
        "    clean_tweet = [ps.stem(word) for word in c_tweets]\n",
        "    clean_tweets.append(clean_tweet)\n",
        "  return clean_tweets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jj7VKJ4TGmvn"
      },
      "outputs": [],
      "source": [
        "\n",
        "positive_tweets=process_sentence(positive_tweets)\n",
        "negative_tweets=process_sentence(negative_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyAS3EzRHPaf",
        "outputId": "d7974ed4-fa85-4c1e-b645-0524093169fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['top', 'engag', 'member', 'commun', 'week']\n",
            "['hey', 'jame', 'odd', '/', 'pleas', 'call', 'contact', 'centr', 'onand', 'abl', 'assist', 'mani', 'thank']\n",
            "['listen', 'last', 'night', 'bleed', 'amaz', 'track', 'scotland']\n",
            "['congrat']\n",
            "['yeaaaah', 'yippppi', 'accnt', 'verifi', 'rqst', 'succeed', 'got', 'blue', 'tick', 'mark', 'fb', 'profil', 'inday']\n",
            "['one', 'irresist']\n",
            "[\"n't\", 'like', 'keep', 'love', 'custom', 'wait', 'long', 'hope', 'enjoy', 'happi', 'friday', '-', 'lwwf']\n",
            "['second', 'thought', '’', 'enough', 'time', 'dd', 'new', 'short', 'enter', 'system', 'sheep', 'must', 'buy']\n",
            "['jgh', 'go', 'bayan', 'bye']\n",
            "['act', 'mischiev', 'call', 'etl', 'layer', 'in-hous', 'wareh', 'app', 'katamari', 'well…', 'name', 'impli', 'p']\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  print(positive_tweets[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7uGFdMfiH5W0"
      },
      "outputs": [],
      "source": [
        "positive_labels= [1]*len(positive_tweets)\n",
        "negative_labels= [0]*len(negative_tweets)\n",
        "positive_labels.extend(negative_labels)\n",
        "positive_tweets.extend(negative_tweets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs2gFksSIdZE",
        "outputId": "cd6cbf86-14ec-4fb0-f93d-f9c56e72fcd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "labels =  positive_labels\n",
        "tweets = positive_tweets\n",
        "print(len(labels))\n",
        "print(len(tweets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "C5MhQy1oJLF0"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "zip_list = list(zip(tweets,labels))\n",
        "random.shuffle(zip_list)\n",
        "tweets,labels = zip(*zip_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hHO_0e6TLyhF"
      },
      "outputs": [],
      "source": [
        "def build_freq(tweets,labels):\n",
        "    freq={}\n",
        "\n",
        "    #iterat tweets\n",
        "    for i in range(len(tweets)):\n",
        "        #iterate on each word in each tweets\n",
        "        for word in tweets[i]:\n",
        "            key=word\n",
        "            if key not in freq.keys():### frist time\n",
        "                if labels[i]==1:\n",
        "                    freq[key]=[1,0]#positive class\n",
        "                else:\n",
        "                    freq[key]=[0,1]#negative class\n",
        "            else:\n",
        "                if labels[i]==1:### exist before\n",
        "                    freq[key][0]+=1\n",
        "                else:\n",
        "                    freq[key][1]+=1\n",
        "\n",
        "    return freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KeQSw7nHMaUu"
      },
      "outputs": [],
      "source": [
        "freq_table = build_freq(tweets,labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ics46ll3M-Tj",
        "outputId": "f5be3a70-3c52-4005-b771-db6703196fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30219\n",
            "29142\n"
          ]
        }
      ],
      "source": [
        "sum_pos_freq = 0\n",
        "sum_Neg_freq = 0\n",
        "for key in freq_table.keys():\n",
        "  sum_pos_freq += freq_table[key][0]\n",
        "  sum_Neg_freq += freq_table[key][1]\n",
        "\n",
        "print(sum_pos_freq)\n",
        "print(sum_Neg_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-u0vm3VNyO1",
        "outputId": "60b6c4e9-42b5-45f4-d458-63bd069e6073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10089\n"
          ]
        }
      ],
      "source": [
        "V= len(freq_table)\n",
        "print(V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xLr2KjbDOPkE"
      },
      "outputs": [],
      "source": [
        "def build_probability(freq_table, sum_pos_freq, sum_Neg_freq, V):\n",
        "  prob_table={}\n",
        "  for key in freq_table.keys():\n",
        "    prob_table[key]= [(freq_table[key][0]+1)/(sum_pos_freq+V), (freq_table[key][1]+1)/(sum_Neg_freq+V)]\n",
        "  return prob_table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "o17GuoEMOzSj"
      },
      "outputs": [],
      "source": [
        "prob_dict = build_probability(freq_table=freq_table, sum_pos_freq=sum_pos_freq, sum_Neg_freq=sum_Neg_freq, V=V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rhZMVjMCPERt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def Naive_Bayes_inference(tweets, prop_dict):\n",
        "  results = []\n",
        "  for tweet in tweets:\n",
        "    result = 0\n",
        "    for word in tweet:\n",
        "      try:\n",
        "        result += np.log(prob_dict[word][0]/ prob_dict[word][1])# ratio\n",
        "      except:\n",
        "        result +=0\n",
        "    results.append(result)\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8uYd93uUQmHW"
      },
      "outputs": [],
      "source": [
        "y_pred = Naive_Bayes_inference(tweets, prop_dict=freq_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "olnYp2ARRF-k"
      },
      "outputs": [],
      "source": [
        "y_p = [i if y>=0 else 0 for y  in y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq-U2H6lRNXV",
        "outputId": "fd465627-8f7c-45e4-8f2b-d56b35d552f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4374"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(labels, y_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tgxV39PVRRgj"
      },
      "outputs": [],
      "source": [
        "test_tweets=[\"@metalgear_jp @Kojima_Hideo I want you're T-shirts ! They are so cool ! :D\",\"Stats for the day have arrived. 2 new followers and NO unfollowers :) via http://t.co/xxlXs6xYwe.\",\n",
        "             \"Dang that is some rad @AbzuGame #fanart! :D https://t.co/bI8k8tb9ht\",\"Can u feel it? :((:( #exo http://t.co/ghsa262ORm\",\"@seanactual You mean you're not offering? :(\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8ojkhSNRv_p",
        "outputId": "ee5385e3-0880-4712-e70a-a7bec1b7fdf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['want', \"'re\", 't-shirt', 'cool'],\n",
              " ['stat', 'day', 'arrivednew', 'follow', 'unfollow', 'via'],\n",
              " ['dang', 'rad'],\n",
              " ['u', 'feel'],\n",
              " ['mean', \"'re\", 'offer']]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_tweet = process_sentence(test_tweets)\n",
        "clean_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv0CbUE2SM5k",
        "outputId": "022e5e29-4208-477e-a132-13b223a17a13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[np.float64(2.7126399671171493),\n",
              " np.float64(13.008719656930369),\n",
              " np.float64(1.0444468690167477),\n",
              " np.float64(-1.0111916407347108),\n",
              " np.float64(-0.22540661467585196)]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Naive_Bayes_inference(clean_tweet, prob_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clo0rsPlS4kx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
